Readme for Exploring Multimodal Interaction with Virtual Pets in VR

Project Overview:
-----------------
This project is related to exploring how people interact with pets in Virtual Reality (VR) using different modalities such as controllers, gaze, and speech. The goal is to analyze how these interaction methods impact the experience and engagement of users with virtual pets in a VR environment. You can explore the details in the video and Overleaf document linked below.

Links:
------
**Project Video (YouTube - Unlisted)**:
   - Checkpoint 1 - https://youtu.be/h53HzYw4db4

**Overleaf Document**:
   - Checkpoint 1  https://www.overleaf.com/read/rpczykrnkfrj#29d5a2

Additional Information:
------------------------
-The project is developed using Unity and the Oculus Quest 2 VR set for the development of the 	virtual reality experience. The main components include utilizing Unity 3D for environment and interaction design, and Oculus SDK for the integration of VR features.

Key aspects of the project include:

-Exploring how people interact with pets in VR through different modalities such as controllers, gaze, and speech.

-The experiment will include mockups and descriptions of the independent and dependent variables involved in the VR interaction study.

-The final deliverable will be a detailed PDF report that includes an analysis of the experimentâ€™s results, project details, and references to updated articles.

-If you encounter any issues or have questions, please feel free to reach out via email at rocarrol@colostate.edu or through the Overleaf link provided for collaboration on the document.

Thank you for reviewing the project!
